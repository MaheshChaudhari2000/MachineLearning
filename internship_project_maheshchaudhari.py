# -*- coding: utf-8 -*-
"""Internship_project_MaheshChaudhari (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I8wkPyfoeFsnrJnZAhIexTzJfEttUVzw

# Here I am training the data in **train.csv file**
"""

### Project part 1-4 

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Here I am importing the data

data_train = pd.read_csv("train.csv")

data_train.head()

data_train.shape

# Here I am changing categories to numerical values

category = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8}

data_train["category"] = data_train["category"].map(category)

data_train.head()

# Visualization
# Individual Plots
plt.hist(data_train["category"])
plt.show()
plt.plot(data_train["adview"])
plt.show()

# Remove videos with adview greater than 2000000 as outlier
data_train = data_train[data_train["adview"] <2000000]
# Heatmap
import seaborn as sns

f, ax = plt.subplots(figsize=(10, 8))

corr = data_train.corr()
sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),
            square=True, ax=ax,annot=True)
plt.show()

# Here I am removing the character 'F' from the given dataset 

data_train=data_train[data_train.views !='F']
data_train=data_train[data_train.likes !='F']
data_train=data_train[data_train.dislikes !='F']
data_train=data_train[data_train.comment !='F']

data_train.head()

# Here I am converting the data to numeric format which right now is in a string format 

data_train["views"] = pd.to_numeric(data_train["views"])
data_train["comment"] = pd.to_numeric(data_train["comment"])
data_train["likes"] = pd.to_numeric(data_train["likes"])
data_train["dislikes"] = pd.to_numeric(data_train["dislikes"])
data_train["adview"]=pd.to_numeric(data_train["adview"])

## storing it in a column named column_vivid

column_vivid = data_train['vidid']

from sklearn.preprocessing import LabelEncoder
data_train['duration']=LabelEncoder().fit_transform(data_train['duration'])
data_train['vidid']=LabelEncoder().fit_transform(data_train['vidid'])
data_train['published']=LabelEncoder().fit_transform(data_train['published'])
data_train.head()

# Converting Time in sec for duration (part of data transformation)

import datetime
import time

def checki(x):
    y = x[2:]
    h = ''
    m = ''
    s = ''
    mm = ''
    P = ['H','M','S']

    for i in y:
      if i not in P:
        mm+=i
      else:
        if (i=="H"):
          h = mm
          mm = ''
        elif (i == "M"):
          m = mm
          mm = ''
        else:
          s = mm
          mm = ''

    if (h==''):
      h = '00'
    if (m == ''):
      m = '00'
    if (s==''):
      s='00'
    bp = h+':'+m+':'+s
    return bp


train=pd.read_csv("train.csv")
mp = pd.read_csv("train.csv")["duration"]
time = mp.apply(checki)


def func_sec(time_string):
  h, m, s = time_string.split(':')
  return int(h) * 3600 + int(m) * 60 + int(s)


time1=time.apply(func_sec)
data_train["duration"]=time1
data_train.head()

### Project Part 5

# Split Data

Y_train = pd.DataFrame(data = data_train.iloc[:, 1].values, columns = ['target'])

data_train=data_train.drop(['adview'], axis=1)
data_train=data_train.drop(['vidid'], axis=1)
data_train.head()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(data_train, Y_train, test_size=0.2, random_state=42)

Y_train

# Normalise Data

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_train=scaler.fit_transform(X_train)
X_test=scaler.fit_transform(X_test)

print(X_train.mean())
print(X_test.mean())

### Project part 6 and 7 

# Evaluation Metrics

from sklearn import metrics

def print_error(X_test, y_test, model_name):
  prediction = model_name.predict(X_test)
  print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, prediction))
  print('Mean Squared Error:', metrics.mean_squared_error(y_test, prediction))
  print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, prediction)))

# Linear Regression

from sklearn import linear_model
linear_regression = linear_model.LinearRegression()
linear_regression.fit(X_train, y_train)
print_error(X_test,y_test, linear_regression)

# Support Vector Regressor

from sklearn.svm import SVR
supportvector_regressor = SVR()
supportvector_regressor.fit(X_train,y_train)
print_error(X_test,y_test, linear_regression)

# Decision Tree Regressor

from sklearn.tree import DecisionTreeRegressor
decision_tree = DecisionTreeRegressor()
decision_tree.fit(X_train, y_train)
print_error(X_test,y_test, decision_tree)

# Random Forest Regressor

from sklearn.ensemble import RandomForestRegressor
n_estimators = 200
max_depth = 25
min_samples_split=15
min_samples_leaf=2
random_forest = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, min_samples_split=min_samples_split)

random_forest.fit(X_train,y_train)

print_error(X_test,y_test, random_forest)

### Project Part 8-10

# Artificial Neural Network
import keras
from keras.layers import Dense
ann = keras.models.Sequential([
                               Dense(6, activation="relu",
                                     input_shape=X_train.shape[1:]),
                               Dense(6,activation="relu"),
                               Dense(1)
                               ])

optimizer=keras.optimizers.Adam()
loss=keras.losses.mean_squared_error
ann.compile(optimizer=optimizer,loss=loss,metrics=["mean_squared_error"])

history=ann.fit(X_train,y_train,epochs=100)
ann.summary()
print_error(X_test,y_test,ann)


#Saving Scikitlearn models

import joblib

joblib.dump(decision_tree, "decisiontree_youtubeadview.pkl")

# Saving Keras Artificial Neural Network model
ann.save("ann_youtubeadview.h5")



"""# Here I am operating the data in the **test.csv file** i.e. first cleaning and then predicting"""

### Project part 1-4 

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Here I am importing the data

data_test = pd.read_csv("test.csv")

data_test.head()

data_test.shape

# Here I am changing categories to numerical values

category = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8}

data_test["category"] = data_test["category"].map(category)

data_test.head()

# Visualization
# Individual Plots
plt.hist(data_test["category"])
plt.show()

# Here I am removing the character 'F' from the given dataset 

data_test=data_test[data_test.views !='F']
data_test=data_test[data_test.likes !='F']
data_test=data_test[data_test.dislikes !='F']
data_test=data_test[data_test.comment !='F']

data_test.head()

# Here I am converting the data to numeric format which right now is in a string format 



data_test['views'] = pd.to_numeric(data_test['views'])
data_test["comment"] = pd.to_numeric(data_test["comment"])
data_test["likes"] = pd.to_numeric(data_test["likes"])
data_test["dislikes"] = pd.to_numeric(data_test["dislikes"])

## storing it in a column named column_vivid

from sklearn.preprocessing import LabelEncoder
data_test['duration']=LabelEncoder().fit_transform(data_test['duration'])

data_test['published']=LabelEncoder().fit_transform(data_test['published'])
data_test.head()

# Converting Time in sec for duration (part of data transformation)

import datetime
import time

def checki(x):
    y = x[2:]
    h = ''
    m = ''
    s = ''
    mm = ''
    P = ['H','M','S']

    for i in y:
      if i not in P:
        mm+=i
      else:
        if (i=="H"):
          h = mm
          mm = ''
        elif (i == "M"):
          m = mm
          mm = ''
        else:
          s = mm
          mm = ''

    if (h==''):
      h = '00'
    if (m == ''):
      m = '00'
    if (s==''):
      s='00'
    bp = h+':'+m+':'+s
    return bp


test=pd.read_csv("test.csv")
mp = pd.read_csv("test.csv")["duration"]
time = mp.apply(checki)


def func_sec(time_string):
  h, m, s = time_string.split(':')
  return int(h) * 3600 + int(m) * 60 + int(s)


time1=time.apply(func_sec)
data_test["duration"]=time1
data_test.head()

### Project Part 5

# Split Data

B_train = pd.DataFrame(data = data_test.iloc[:, 1].values, columns = ['target'])
data_test=data_test.drop(['vidid'], axis=1)

data_test.head()

# Normalise Data

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
data_test=scaler.fit_transform(data_test)
data_test.mean()

"""# Using my best model i.e. **Random Forest Regressor** to predict the 'adview' values for test.csv file"""

# Random Forest Regressor

from sklearn.ensemble import RandomForestRegressor
import pandas as pd

n_estimators = 200
max_depth = 25
min_samples_split=15
min_samples_leaf=2
random_forest = RandomForestRegressor(n_estimators = n_estimators, max_depth = max_depth, min_samples_split=min_samples_split)

random_forest.fit(X_train,y_train)

adview_predictions = random_forest.predict(data_test)
print(adview_predictions)

import numpy as np
import pandas as pd

adview_predictions = pd.DataFrame(adview_predictions, columns=['adview_predictions']).to_csv('test.csv')

data_test.shape

